{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksFajfelNLD0",
        "outputId": "4a7217e7-ba1e-4f6f-e2b7-bf400b99fae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'higan'...\n",
            "remote: Enumerating objects: 288, done.\u001b[K\n",
            "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 288 (delta 77), reused 263 (delta 58), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (288/288), 16.22 MiB | 10.31 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'higan'\n",
        "!git clone https://github.com/genforce/higan.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "!mkdir -p models/pretrain/pytorch\n",
        "!wget https://www.dropbox.com/s/h1w7ld4hsvte5zf/stylegan_bedroom256_generator.pth?dl=1 -O models/pretrain/pytorch/stylegan_bedroom256_generator.pth --quiet\n",
        "!wget https://www.dropbox.com/s/hwjyclj749qtp89/order_w.npy?dl=1 -O order_w_1k.npy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach\n",
        "!pip install lpips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PSeCfFbNccw",
        "outputId": "a2d0b48e-f8af-470f-e047-a9c0dfb306b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn as nn\n",
        "import lpips\n",
        "\n",
        "from models.helper import build_generator\n",
        "from utils.logger import setup_logger\n",
        "from utils.editor import get_layerwise_manipulation_strength\n",
        "from utils.editor import manipulate\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "\n",
        "\n",
        "# LPIPS 손실 초기화\n",
        "# GPU가 사용 가능한 경우 CUDA를 사용하고, 그렇지 않으면 CPU를 사용하도록 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# LPIPS 손실 함수 초기화, 'alex' 네트워크를 사용\n",
        "lpips_loss_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "# Perceptual Loss(지각적 손실) 를 위해 VGG 초기화\n",
        "# 사전 학습된 VGG16 네트워크의 첫 16개의 레이어만 사용하고 평가 모드로 설정\n",
        "vgg = vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features[:16].eval().to(device)\n",
        "# VGG 네트워크의 매개변수(가중치)들이 학습되지 않도록 설정\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "def imshow(images, col, viz_size=256):\n",
        "    \"\"\"하나의 그림에 여러 이미지를 표시\"\"\"\n",
        "    num, height, width, channels = images.shape\n",
        "    assert num % col == 0  # 열로 나누어 떨어지는지 확인\n",
        "    row = num // col  # 행의 수 계산\n",
        "\n",
        "    # 전체 이미지를 담을 빈 캔버스 생성\n",
        "    fused_image = np.zeros((viz_size * row, viz_size * col, channels), dtype=np.uint8)\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        i, j = divmod(idx, col)  # 인덱스를 행, 열 위치로 변환\n",
        "        y = i * viz_size  # y 축 위치 계산\n",
        "        x = j * viz_size  # x 축 위치 계산\n",
        "        if height != viz_size or width != viz_size:  # 이미지 크기가 지정한 시각화 크기와 다르면\n",
        "            image = cv2.resize(image, (viz_size, viz_size))  # 이미지 크기 조정\n",
        "        fused_image[y:y + viz_size, x:x + viz_size] = image  # 캔버스에 이미지를 붙임\n",
        "\n",
        "    fused_image = np.asarray(fused_image, dtype=np.uint8)  # 정수형 배열로 변환\n",
        "    data = io.BytesIO()  # 메모리 내 바이너리 데이터 버퍼 생성\n",
        "    PIL.Image.fromarray(fused_image).save('test.jpeg', 'jpeg')  # 이미지를 JPEG 형식으로 저장\n",
        "    im_data = data.getvalue()  # 바이너리 데이터로 변환\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))  # 이미지 표시\n",
        "    return disp\n",
        "\n",
        "def build_model(model_name, logger=None):\n",
        "    \"\"\"모델 이름에 따라 생성기를 빌드합니다.\"\"\"\n",
        "    model = build_generator(model_name, logger=logger)  # 모델 빌드 함수 호출\n",
        "    return model\n",
        "\n",
        "def sample_codes(model, num, seed=0, w1k_code=None):\n",
        "    \"\"\"랜덤으로 잠재 코드를 샘플링합니다.\"\"\"\n",
        "    np.random.seed(seed)  # 난수 시드 설정\n",
        "    if w1k_code is None:  # w1k 코드가 없는 경우\n",
        "        latent_codes = model.easy_sample(num=num, latent_space_type='w')  # w 잠재 공간에서 샘플링\n",
        "    else:  # w1k 코드가 있는 경우\n",
        "        latent_codes = w1k_code[np.random.randint(0, w1k_code.shape[0], num)]  # w1k 코드에서 무작위로 선택\n",
        "    # 샘플된 잠재 코드를 w 공간에 맞게 변환하고 스타일 및 이미지 생성 없이 반환\n",
        "    latent_codes = model.easy_synthesize(latent_codes=latent_codes,\n",
        "                                         latent_space_type='w',\n",
        "                                         generate_style=False,\n",
        "                                         generate_image=False)['wp']\n",
        "    return latent_codes\n",
        "\n",
        "def calculate_total_variation_loss(image):\n",
        "    \"\"\"이미지의 매끄러움을 위한 총 변동 손실(Total Variation Loss)\"\"\"\n",
        "    tv_loss = torch.sum(torch.abs(image[:, :, :, :-1] - image[:, :, :, 1:])) + \\\n",
        "              torch.sum(torch.abs(image[:, :, :-1, :] - image[:, :, 1:, :]))  # 인접한 픽셀 간의 차이의 합계 계산\n",
        "    return tv_loss\n",
        "\n",
        "def perceptual_loss(input_image, generated_image):\n",
        "    \"\"\"VGG16을 사용하는 지각적 손실(Perceptual Loss)\"\"\"\n",
        "    input_features = vgg(input_image)  # 입력 이미지의 특징 추출\n",
        "    generated_features = vgg(generated_image)  # 생성된 이미지의 특징 추출\n",
        "    return F.mse_loss(input_features, generated_features)  # 특징 간의 평균 제곱 오차(MSE) 계산\n",
        "\n",
        "def color_loss(input_image, generated_image):\n",
        "    \"\"\"색상 일관성 손실(Color Consistency Loss)\"\"\"\n",
        "    input_color = torch.mean(input_image, dim=(2, 3), keepdim=True)  # 입력 이미지의 평균 색상 계산\n",
        "    generated_color = torch.mean(generated_image, dim=(2, 3), keepdim=True)  # 생성된 이미지의 평균 색상 계산\n",
        "    return F.mse_loss(input_color, generated_color)  # 평균 색상 간의 MSE 손실 계산\n",
        "\n",
        "def preprocess_image(image_path, device):\n",
        "    \"\"\"입력 이미지를 불러오고 전처리합니다.\"\"\"\n",
        "    if not os.path.exists(image_path):  # 이미지 경로가 존재하지 않으면 예외 발생\n",
        "        raise FileNotFoundError(f\"입력 이미지를 {image_path} 경로에서 찾을 수 없습니다.\")\n",
        "    image = PIL.Image.open(image_path).convert('RGB')  # 이미지를 열고 RGB로 변환\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),  # 256x256 크기로 조정\n",
        "        transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)  # 배치 차원을 추가하고 장치로 전송\n",
        "    return image_tensor\n",
        "\n",
        "def approximate_latent_code(image_path, model, num_steps=1500, lr=0.01, num_initializations=10):\n",
        "    \"\"\"인코더 없이 입력 이미지를 잠재 공간에서 근사(latent code)를 최적화\"\"\"\n",
        "    input_tensor = preprocess_image(image_path, device)\n",
        "\n",
        "    # 여러 초기화를 통해 잠재 코드를 초기화하고 최적의 결과를 추적\n",
        "    best_latent_code = None\n",
        "    best_loss = float('inf')\n",
        "    best_image = None  # 가장 작은 손실 값을 가지는 이미지를 저장\n",
        "\n",
        "    for initialization in range(num_initializations):\n",
        "        # 잠재 공간에서 랜덤한 잠재 코드를 초기화 (평균 0.1)\n",
        "        latent_code = (torch.randn(1, 14, 512, device=device) * 0.1).requires_grad_(True)\n",
        "\n",
        "        # 옵티마이저와 학습률 스케줄러 설정\n",
        "        optimizer = torch.optim.Adam([latent_code], lr=lr)\n",
        "        scheduler = StepLR(optimizer, step_size=500, gamma=0.5)\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            optimizer.zero_grad()  # 그래디언트 초기화\n",
        "\n",
        "            # 잠재 코드를 기반으로 이미지를 생성\n",
        "            latent_code_np = latent_code.detach().cpu().numpy()\n",
        "\n",
        "            # 잠재 코드의 형태가 올바른지 확인하고 차원 확장\n",
        "            if latent_code_np.ndim == 2:\n",
        "                latent_code_np = latent_code_np[np.newaxis, ...]\n",
        "\n",
        "            generated_data = model.easy_synthesize(latent_code_np, latent_space_type='wp')\n",
        "            generated_image = generated_data['image']\n",
        "\n",
        "            # 생성된 이미지를 텐서로 변환하여 학습 가능 상태로 만듦\n",
        "            generated_image_tensor = torch.tensor(\n",
        "                generated_image.transpose(0, 3, 1, 2), dtype=torch.float32, device=device\n",
        "            ) / 255.0\n",
        "            generated_image_tensor.requires_grad_()\n",
        "\n",
        "            # 손실 계산\n",
        "            mse_loss = F.mse_loss(generated_image_tensor, input_tensor) * 100.0  # MSE 손실\n",
        "            tv_loss = calculate_total_variation_loss(generated_image_tensor) * 0.005  # TV 손실\n",
        "            perceptual = perceptual_loss(input_tensor, generated_image_tensor) * 40.0  # Perceptual 손실\n",
        "            lpips_loss = lpips_loss_fn(input_tensor, generated_image_tensor).mean() * 30.0  # LPIPS 손실\n",
        "\n",
        "            # 총 손실\n",
        "            total_loss = mse_loss + tv_loss + perceptual + lpips_loss\n",
        "\n",
        "            # 역전파 수행 및 파라미터 업데이트\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # 중간 결과 로깅\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Initialization [{initialization + 1}/{num_initializations}], Step [{step}/{num_steps}], Total Loss: {total_loss.item()}\")\n",
        "                print(f\"MSE Loss: {mse_loss.item()}, TV Loss: {tv_loss.item()}, Perceptual Loss: {perceptual.item()}, LPIPS Loss: {lpips_loss.item()}\")\n",
        "\n",
        "        # 초기화별 생성된 이미지를 저장\n",
        "        generated_image_np = (generated_image_tensor[0].detach().cpu().numpy().transpose(1, 2, 0) * 255).clip(0, 255).astype(np.uint8)\n",
        "        PIL.Image.fromarray(generated_image_np).save(f\"generated_initialization_{initialization + 1}.jpeg\")\n",
        "\n",
        "        # 가장 작은 손실 값을 가진 잠재 코드와 이미지를 저장\n",
        "        if total_loss.item() < best_loss:\n",
        "            best_latent_code = latent_code.clone().detach()\n",
        "            best_loss = total_loss.item()\n",
        "            best_image = generated_image_np  # 손실 값이 가장 작은 이미지를 저장\n",
        "\n",
        "    # 최적의 잠재 코드에서 이미지를 생성\n",
        "    best_latent_code_np = best_latent_code.detach().cpu().numpy()\n",
        "\n",
        "    # 잠재 코드의 형태가 올바른지 확인하고 차원 확장\n",
        "    if best_latent_code_np.ndim == 2:\n",
        "        best_latent_code_np = best_latent_code_np[np.newaxis, ...]\n",
        "\n",
        "    final_data = model.easy_synthesize(best_latent_code_np, latent_space_type='wp')\n",
        "    final_image = final_data['image']\n",
        "\n",
        "    # 최종 이미지를 저장\n",
        "    final_image_np = (final_image[0] * 255).clip(0, 255).astype(np.uint8)\n",
        "    PIL.Image.fromarray(final_image_np).save(\"final_best_generated_image.jpeg\")\n",
        "    print(\"Final generated image saved as 'final_best_generated_image.jpeg'.\")\n",
        "\n",
        "    # 손실 값이 가장 작은 이미지를 저장\n",
        "    if best_image is not None:\n",
        "        PIL.Image.fromarray(best_image).save(\"best_image_with_min_loss.jpeg\")\n",
        "        print(\"Best image with minimum loss saved as 'best_image_with_min_loss.jpeg'.\")\n",
        "\n",
        "    return best_latent_code_np\n",
        "\n",
        "w1k_code = np.load('order_w_1k.npy')  # 사전 학습된 잠재 코드(w1k 코드) 파일을 불러옵니다.\n",
        "\n",
        "indoor_model_name = \"stylegan_bedroom\"  # 사용하려는 모델의 이름을 지정합니다.\n",
        "indoor_model = build_model(indoor_model_name)  # 지정된 이름으로 모델을 빌드합니다.\n",
        "\n",
        "# 입력 이미지 불러오기 및 잠재 코드로 변환하기\n",
        "input_image_path = '/content/10_445_6.png'  # 입력 이미지의 경로를 설정합니다.\n",
        "if os.path.exists(input_image_path):  # 입력 이미지 파일이 존재하는지 확인합니다.\n",
        "  input_latent_code = approximate_latent_code(input_image_path, indoor_model)  # 입력 이미지를 잠재 코드로 근사합니다.\n",
        "else:\n",
        "  raise FileNotFoundError(f\"Input image not found at {input_image_path}\")  # 파일이 존재하지 않으면 예외를 발생시킵니다.\n",
        "\n",
        "# 여러 샘플을 생성하고 싶다면, 잠재 코드를 복제하여 사용합니다.\n",
        "num_samples = 8  # 생성할 샘플 수를 설정합니다.\n",
        "indoor_latent_codes = np.tile(input_latent_code, (num_samples, 1, 1))  # 입력 잠재 코드를 복제합니다.\n",
        "\n",
        "synthesis_kwargs = {'latent_space_type': 'wp'}  # 잠재 공간 유형을 지정합니다.\n",
        "\n",
        "# 잠재 코드로부터 이미지를 생성합니다.\n",
        "images = indoor_model.easy_synthesize(indoor_latent_codes, **synthesis_kwargs)['image']  # 잠재 코드로 이미지를 합성합니다.\n",
        "imshow(images, col=num_samples)  # 생성된 이미지를 화면에 표시합니다.\n",
        "\n",
        "#@title { display-mode: \"form\", run: \"auto\" }\n",
        "attribute_name = 'indoor_lighting'  # 조작할 속성을 설정합니다. ['indoor_lighting', 'wood', 'cluttered_space', 'view'] 중 하나를 선택합니다.\n",
        "path = f'boundaries/{indoor_model_name}/{attribute_name}_boundary.npy'  # 속성 경계 파일의 경로를 설정합니다.\n",
        "\n",
        "try:\n",
        "  boundary_file = np.load(path, allow_pickle=True).item()  # 경계 파일을 불러옵니다.\n",
        "  boundary = boundary_file['boundary']  # 경계 데이터를 추출합니다.\n",
        "  manipulate_layers = boundary_file['meta_data']['manipulate_layers']  # 조작할 레이어 정보를 추출합니다.\n",
        "except ValueError:\n",
        "  boundary = np.load(path)  # 경계 파일을 불러옵니다.\n",
        "  if attribute_name == 'view':\n",
        "    manipulate_layers = '0-4'  # 'view' 속성의 경우, 조작할 레이어를 설정합니다.\n",
        "  else:\n",
        "    manipulate_layers = '6-11'  # 기본 조작 레이어 설정입니다.\n",
        "\n",
        "if attribute_name == 'view':\n",
        "  strength = [1.0 for _ in range(indoor_model.num_layers)]  # 'view' 속성에 대한 강도를 설정합니다.\n",
        "else:\n",
        "  strength = get_layerwise_manipulation_strength(\n",
        "    indoor_model.num_layers, indoor_model.truncation_psi, indoor_model.truncation_layers)  # 레이어별 조작 강도를 가져옵니다.\n",
        "\n",
        "# 잠재 코드를 조작하여 새 이미지를 생성합니다.\n",
        "distance = -3  #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}  # 속성 조작의 거리를 설정합니다.\n",
        "indoor_codes = manipulate(latent_codes=indoor_latent_codes,\n",
        "                     boundary=boundary,\n",
        "                     start_distance=0,\n",
        "                     end_distance=distance,\n",
        "                     step=2,\n",
        "                     layerwise_manipulation=True,\n",
        "                     num_layers=indoor_model.num_layers,\n",
        "                     manipulate_layers=manipulate_layers,\n",
        "                     is_code_layerwise=True,\n",
        "                     is_boundary_layerwise=False,\n",
        "                     layerwise_manipulation_strength=strength)  # 조작 매개변수를 통해 잠재 코드를 조작합니다.\n",
        "\n",
        "images = indoor_model.easy_synthesize(indoor_codes[:, 1], latent_space_type='wp')['image']  # 조작된 잠재 코드로 이미지를 합성합니다.\n",
        "imshow(images, col=num_samples)  # 생성된 이미지를 화면에 표시합니다.\n",
        "\n",
        "# 생성된 이미지를 저장합니다.\n",
        "np.save('generated_images.npy', images)  # 생성된 이미지를 .npy 파일로 저장합니다.\n",
        "PIL.Image.fromarray(images[0]).save('test.jpeg', 'jpeg')  # 첫 번째 이미지를 .jpeg 파일로 저장합니다.\n",
        "np.save('latent_codes_1.npy', indoor_codes)  # 조작된 잠재 코드를 저장합니다.\n",
        "\n",
        "# 잠재 코드를 다시 조작하여 속성을 더욱 변형합니다.\n",
        "distance = 3  #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}  # 속성 조작의 거리를 설정합니다.\n",
        "indoor_codes2 = manipulate(latent_codes=indoor_latent_codes,\n",
        "                     boundary=boundary,\n",
        "                     start_distance=0,\n",
        "                     end_distance=distance,\n",
        "                     step=2,\n",
        "                     layerwise_manipulation=True,\n",
        "                     num_layers=indoor_model.num_layers,\n",
        "                     manipulate_layers=manipulate_layers,\n",
        "                     is_code_layerwise=True,\n",
        "                     is_boundary_layerwise=False,\n",
        "                     layerwise_manipulation_strength=strength)  # 조작 매개변수를 통해 잠재 코드를 다시 조작합니다.\n",
        "\n",
        "images2 = indoor_model.easy_synthesize(indoor_codes2[:, 1], latent_space_type='wp')['image']  # 새로 조작된 잠재 코드로 이미지를 합성합니다.\n",
        "imshow(images2, col=num_samples)  # 생성된 이미지를 화면에 표시합니다.\n",
        "\n",
        "# 새로 생성된 이미지를 저장합니다.\n",
        "np.save('generated_images_2.npy', images2)  # 생성된 이미지를 .npy 파일로 저장합니다.\n",
        "PIL.Image.fromarray(images2[0]).save('test_2.jpeg', 'jpeg')  # 첫 번째 이미지를 .jpeg 파일로 저장합니다.\n",
        "np.save('latent_codes_2.npy', indoor_codes2)  # 새로 조작된 잠재 코드를 저장합니다.\n",
        "\n",
        "# 원래 잠재 코드와 조작된 잠재 코드 사이의 보간 이미지를 생성합니다.\n",
        "interpolated_images = []  # 보간 이미지를 저장할 리스트입니다.\n",
        "steps = 10  # 보간 단계를 설정합니다.\n",
        "for alpha in np.linspace(0, 1, steps):\n",
        "    interpolated_code = (1 - alpha) * input_latent_code[0, :14, :] + alpha * indoor_codes2[0, :14, :]  # 0과 1 사이의 보간을 수행합니다.\n",
        "    interpolated_images.append(indoor_model.easy_synthesize(interpolated_code, latent_space_type='wp')['image'][0])  # 보간된 코드로 이미지를 생성합니다.\n",
        "\n",
        "interpolated_images = np.array(interpolated_images)  # 보간 이미지를 NumPy 배열로 변환합니다.\n",
        "imshow(interpolated_images, col=steps)  # 보간 이미지를 화면에 표시합니다.\n",
        "\n",
        "# 보간 이미지를 저장합니다.\n",
        "np.save('interpolated_images.npy', interpolated_images)  # 보간 이미지를 .npy 파일로 저장합니다.\n",
        "PIL.Image.fromarray(interpolated_images[0]).save('test_interpolated.jpeg', 'jpeg')  # 첫 번째 보간 이미지를 .jpeg 파일로 저장합니다.\n"
      ],
      "metadata": {
        "id": "x4AyNZbGNh2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d153ad2-9416-480b-a922-f896e567b85a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 227MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 225MB/s]\n",
            "/content/higan/models/base_generator.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(self.weight_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization [1/10], Step [0/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [100/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [200/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [300/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [400/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [500/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [600/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [700/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [800/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [900/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [1000/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [1100/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [1200/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [1300/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [1/10], Step [1400/1500], Total Loss: 305.3810119628906\n",
            "MSE Loss: 7.234801292419434, TV Loss: 50.096805572509766, Perceptual Loss: 229.87298583984375, LPIPS Loss: 18.17643165588379\n",
            "Initialization [2/10], Step [0/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [100/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [200/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [300/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [400/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [500/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [600/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [700/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [800/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [900/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [1000/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [1100/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [1200/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [1300/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [2/10], Step [1400/1500], Total Loss: 317.943603515625\n",
            "MSE Loss: 7.67278528213501, TV Loss: 50.04494094848633, Perceptual Loss: 241.80935668945312, LPIPS Loss: 18.416492462158203\n",
            "Initialization [3/10], Step [0/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [100/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [200/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [300/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [400/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [500/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [600/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [700/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [800/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [900/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [1000/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [1100/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [1200/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [1300/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [3/10], Step [1400/1500], Total Loss: 305.7544860839844\n",
            "MSE Loss: 7.013233661651611, TV Loss: 51.55127716064453, Perceptual Loss: 230.28201293945312, LPIPS Loss: 16.907955169677734\n",
            "Initialization [4/10], Step [0/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [100/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [200/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [300/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [400/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [500/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [600/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [700/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [800/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [900/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [1000/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [1100/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [1200/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [1300/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [4/10], Step [1400/1500], Total Loss: 312.18927001953125\n",
            "MSE Loss: 7.416132926940918, TV Loss: 50.94356918334961, Perceptual Loss: 234.9120330810547, LPIPS Loss: 18.91754150390625\n",
            "Initialization [5/10], Step [0/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [100/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [200/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [300/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [400/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [500/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [600/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [700/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [800/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [900/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [1000/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [1100/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [1200/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [1300/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [5/10], Step [1400/1500], Total Loss: 313.4968566894531\n",
            "MSE Loss: 8.14169692993164, TV Loss: 50.84086227416992, Perceptual Loss: 235.8677978515625, LPIPS Loss: 18.64650535583496\n",
            "Initialization [6/10], Step [0/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [100/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [200/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [300/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [400/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [500/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [600/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [700/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [800/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [900/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [1000/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [1100/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [1200/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [1300/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [6/10], Step [1400/1500], Total Loss: 309.5904846191406\n",
            "MSE Loss: 6.69874382019043, TV Loss: 46.10499954223633, Perceptual Loss: 238.54977416992188, LPIPS Loss: 18.236976623535156\n",
            "Initialization [7/10], Step [0/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [100/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [200/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [300/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [400/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [500/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [600/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [700/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [800/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [900/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [1000/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [1100/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [1200/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [1300/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [7/10], Step [1400/1500], Total Loss: 327.6126403808594\n",
            "MSE Loss: 6.659909248352051, TV Loss: 57.74848937988281, Perceptual Loss: 244.56033325195312, LPIPS Loss: 18.643882751464844\n",
            "Initialization [8/10], Step [0/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [100/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [200/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [300/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [400/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [500/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [600/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [700/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [800/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [900/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [1000/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [1100/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [1200/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [1300/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [8/10], Step [1400/1500], Total Loss: 309.95245361328125\n",
            "MSE Loss: 6.834811687469482, TV Loss: 49.15019989013672, Perceptual Loss: 236.05612182617188, LPIPS Loss: 17.911312103271484\n",
            "Initialization [9/10], Step [0/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [100/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [200/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [300/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [400/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [500/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [600/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [700/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [800/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [900/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [1000/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [1100/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [1200/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [1300/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [9/10], Step [1400/1500], Total Loss: 316.620361328125\n",
            "MSE Loss: 7.639267921447754, TV Loss: 50.13665008544922, Perceptual Loss: 240.52244567871094, LPIPS Loss: 18.322006225585938\n",
            "Initialization [10/10], Step [0/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [100/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [200/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [300/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [400/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [500/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [600/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [700/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [800/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [900/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [1000/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [1100/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [1200/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [1300/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Initialization [10/10], Step [1400/1500], Total Loss: 299.0542297363281\n",
            "MSE Loss: 7.151991844177246, TV Loss: 46.203529357910156, Perceptual Loss: 227.61294555664062, LPIPS Loss: 18.085758209228516\n",
            "Final generated image saved as 'final_best_generated_image.jpeg'.\n",
            "Best image with minimum loss saved as 'best_image_with_min_loss.jpeg'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ietH5c-qN_Xw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}