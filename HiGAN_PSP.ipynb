{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob-zea6r2lwf"
      },
      "source": [
        "# Fetch Codebase and Models (git에서 higan, psp-encoder 파일 불러오기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC7nnp2I2p_s",
        "outputId": "512a9eb0-6fa4-4a55-e412-cc29337a98b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'higan'...\n",
            "remote: Enumerating objects: 288, done.\u001b[K\n",
            "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 288 (delta 77), reused 263 (delta 58), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (288/288), 16.22 MiB | 4.52 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ],
      "source": [
        "# HIGAN 불러오기\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'higan'  # HiGAN 프로젝트를 저장할 디렉토리 이름\n",
        "!git clone https://github.com/genforce/higan.git $CODE_DIR\n",
        "\n",
        "!mkdir -p higan/models/pretrain/pytorch  # HiGAN 모델 파일을 저장할 디렉토리를 생성\n",
        "!wget https://www.dropbox.com/s/h1w7ld4hsvte5zf/stylegan_bedroom256_generator.pth?dl=1 -O higan/models/pretrain/pytorch/stylegan_bedroom256_generator.pth --quiet\n",
        "!wget https://www.dropbox.com/s/hwjyclj749qtp89/order_w.npy?dl=1 -O higan/order_w_1k.npy --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pSp GitHub 저장소 클론\n",
        "!git clone https://github.com/eladrich/pixel2style2pixel.git\n",
        "%cd pixel2style2pixel\n",
        "\n",
        "os.chdir('/content')\n",
        "!mkdir -p pixel2style2pixel/pretrained_models # pSp Encoder 모델 파일을 저장할 디렉토리를 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHmUHfl9aOzF",
        "outputId": "74b65350-f82f-4577-baad-b7c0ebe41cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pixel2style2pixel'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 418 (delta 0), reused 2 (delta 0), pack-reused 414 (from 1)\u001b[K\n",
            "Receiving objects: 100% (418/418), 92.94 MiB | 16.52 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n",
            "/content/pixel2style2pixel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gdown 라이브러리를 설치\n",
        "!pip install gdown"
      ],
      "metadata": {
        "id": "nGPqmlMXYz7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226b39f4-4156-43d8-afb6-5ff91813ee47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# psp_ffhq_encode.pt 다운\n",
        "import gdown\n",
        "\n",
        "file_id = \"1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0\"\n",
        "output_path = \"pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt\"  # 저장 경로\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
      ],
      "metadata": {
        "id": "_PMOUYe6Y1-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "1507a092-792d-4030-dbc0-6225b1b61a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0\n",
            "From (redirected): https://drive.google.com/uc?id=1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0&confirm=t&uuid=9134d280-2469-4e62-a72d-f31e9d8ce672\n",
            "To: /content/pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt\n",
            "100%|██████████| 1.20G/1.20G [00:29<00:00, 41.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C++ 확장을 위한 ninja 설치\n",
        "!apt-get install ninja-build\n",
        "!pip install ninja"
      ],
      "metadata": {
        "id": "gLsK87UXcf6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f28b661-d912-419b-f9c0-c274d508536f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  ninja-build\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 111 kB of archives.\n",
            "After this operation, 358 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n",
            "Fetched 111 kB in 1s (126 kB/s)\n",
            "Selecting previously unselected package ninja-build.\n",
            "(Reading database ... 123633 files and directories currently installed.)\n",
            "Preparing to unpack .../ninja-build_1.10.1-1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.1-1) ...\n",
            "Setting up ninja-build (1.10.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.2-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 확장 캐시 디렉토리를 삭제 후 새로 빌드\n",
        "!rm -rf ~/.cache/torch_extensions"
      ],
      "metadata": {
        "id": "q3kmf9loefCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA 사용 가능 여부 확인 / 버전\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ],
      "metadata": {
        "id": "a3mXSdaTelJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5d2424-2568-4add-edb1-c429bb453573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA available: True\n",
            "CUDA version: 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ELQheL7Akk"
      },
      "source": [
        "# Define Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rBNq-lX7L-v"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "from higan.models.helper import build_generator\n",
        "from higan.utils.logger import setup_logger\n",
        "from higan.utils.editor import get_layerwise_manipulation_strength\n",
        "from higan.utils.editor import manipulate\n",
        "\n",
        "# 이미지 배열 시각화 함수\n",
        "def imshow(images, col, viz_size=256):\n",
        "  \"\"\"Shows images in one figure.\"\"\"\n",
        "  num, height, width, channels = images.shape\n",
        "  assert num % col == 0\n",
        "  row = num // col\n",
        "\n",
        "  fused_image = np.zeros((viz_size * row, viz_size * col, channels), dtype=np.uint8)\n",
        "\n",
        "  for idx, image in enumerate(images):\n",
        "    i, j = divmod(idx, col)\n",
        "    y = i * viz_size\n",
        "    x = j * viz_size\n",
        "    if height != viz_size or width != viz_size:\n",
        "      image = cv2.resize(image, (viz_size, viz_size))\n",
        "    fused_image[y:y + viz_size, x:x + viz_size] = image\n",
        "\n",
        "  fused_image = np.asarray(fused_image, dtype=np.uint8)\n",
        "  data = io.BytesIO()\n",
        "  PIL.Image.fromarray(fused_image).save(data, 'jpeg')\n",
        "  im_data = data.getvalue()\n",
        "  disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  return disp\n",
        "\n",
        "# 모델을 빌드 함수\n",
        "def build_model(model_name, logger=None):\n",
        "  \"\"\"Builds the generator by model name.\"\"\"\n",
        "  model = build_generator(model_name, logger=logger)\n",
        "  return model\n",
        "\n",
        "# latent_code를 반환해주는 함수\n",
        "def sample_codes(model, num, seed=0, w1k_code=None):\n",
        "  \"\"\"Samples latent codes randomly.\"\"\"\n",
        "  np.random.seed(seed)\n",
        "  if w1k_code is None:\n",
        "    codes = generator.easy_sample(num)\n",
        "    latent_codes = model.easy_sample(num=num, latent_space_type='w')\n",
        "  else:\n",
        "    latent_codes = w1k_code[np.random.randint(0, w1k_code.shape[0], num)]\n",
        "  latent_codes = model.easy_synthesize(latent_codes=latent_codes,\n",
        "                                       latent_space_type='w',\n",
        "                                       generate_style=False,\n",
        "                                       generate_image=False)['wp']\n",
        "  return latent_codes\n",
        "\n",
        "# 사전 정의된 'w' 잠재 코드 로드\n",
        "w1k_code = np.load('/content/higan/order_w_1k.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5SimJ4B8NiM"
      },
      "source": [
        "# Build Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRL0zAeR8TKF"
      },
      "outputs": [],
      "source": [
        "indoor_model_name = \"stylegan_bedroom\"\n",
        "indoor_model = build_model(indoor_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5kDoDmCVBLm"
      },
      "source": [
        "# latent code 저장"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from argparse import Namespace\n",
        "\n",
        "# 프로젝트 디렉토리를 PYTHONPATH에 추가\n",
        "project_dir = '/content/pixel2style2pixel'\n",
        "sys.path.append(project_dir)\n",
        "\n",
        "from pixel2style2pixel.models.psp import pSp  # psp 인코더\n",
        "\n",
        "# -------------------- 장치 설정 --------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------- pSp 인코더 로드 --------------------\n",
        "# pSp 설정 정의\n",
        "opts = Namespace(\n",
        "    checkpoint_path='/content/pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt',  # pSp 인코더 가중치 경로\n",
        "    device=device,  # GPU/CPU 설정\n",
        "    output_size=1024,  # 출력 이미지 해상도\n",
        "    encoder_type='GradualStyleEncoder',  # 인코더 타입\n",
        "    input_nc=3  # 입력 이미지 채널 수 (RGB: 3)\n",
        ")\n",
        "\n",
        "# pSp 초기화\n",
        "psp_encoder = pSp(opts)\n",
        "\n",
        "# pSp 가중치 로드\n",
        "psp_state_dict = torch.load(opts.checkpoint_path, map_location=device)['state_dict']\n",
        "psp_encoder.load_state_dict(psp_state_dict)\n",
        "psp_encoder = psp_encoder.to(device)\n",
        "psp_encoder.eval()  # 평가 모드 설정\n",
        "\n",
        "# -------------------- 입력 이미지 전처리 --------------------\n",
        "# 이미지 전처리 함수\n",
        "def preprocess_image(image_path, device):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # [-1, 1] 범위로 정규화\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "# 이미지 경로\n",
        "input_image_path = '/content/room3.png'  # 변환할 입력 이미지 경로\n",
        "input_image = preprocess_image(input_image_path, device)\n",
        "\n",
        "# -------------------- pSp 인코더를 통한 잠재 코드 생성 --------------------\n",
        "with torch.no_grad():\n",
        "    latent_code = psp_encoder.encoder(input_image)  # 잠재 코드 생성\n",
        "\n",
        "# -------------------- 잠재 코드 저장 --------------------\n",
        "latent_code_numpy = latent_code.cpu().numpy()  # GPU 텐서를 CPU로 이동 후 NumPy 배열로 변환\n",
        "np.save('latent_codes.npy', latent_code_numpy)  # latent space 저장\n",
        "print(\"Latent codes saved successfully!\")\n",
        "\n",
        "# -------------------- 저장된 잠재 코드 확인 --------------------\n",
        "latent_codes_loaded = np.load('latent_codes.npy')\n",
        "print(\"Loaded latent codes shape:\", latent_codes_loaded.shape)"
      ],
      "metadata": {
        "id": "PAQDThQztZC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef35acc-39fb-4fe2-98d2-ff85d3277fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pSp from checkpoint: /content/pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-9496b3d47fd3>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  psp_state_dict = torch.load(opts.checkpoint_path, map_location=device)['state_dict']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent codes saved successfully!\n",
            "Loaded latent codes shape: (1, 18, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleGAN에서 Latent Codes 이미지 생성 시도"
      ],
      "metadata": {
        "id": "HibUNVZnBt9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "M26UU6HrJ5Ki",
        "outputId": "9bdaabaa-3d78-4658-ecba-d14b3f52c410"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Latent codes should be with shape [num, num_layers, *code_shape], where `num_layers` equals to 14, but (1, 18, 512) is received!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-69253d2e32cd>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# 조작 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m  \u001b[0;31m# 조작 거리 (-3.0 ~ 3.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m indoor_codes = manipulate(\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mlatent_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_code_numpy\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# NumPy 배열 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboundary_numpy\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# NumPy 배열 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/higan/utils/editor.py\u001b[0m in \u001b[0;36mmanipulate\u001b[0;34m(latent_codes, boundary, start_distance, end_distance, step, layerwise_manipulation, num_layers, manipulate_layers, is_code_layerwise, is_boundary_layerwise, layerwise_manipulation_strength)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       raise ValueError(f'Latent codes should be with shape [num, num_layers, '\n\u001b[0m\u001b[1;32m    301\u001b[0m                        \u001b[0;34mf'*code_shape], where `num_layers` equals to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                        f'{num_layers}, but {x.shape} is received!')\n",
            "\u001b[0;31mValueError\u001b[0m: Latent codes should be with shape [num, num_layers, *code_shape], where `num_layers` equals to 14, but (1, 18, 512) is received!"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "attribute_name = 'indoor_lighting'  # @param ['indoor_lighting', 'wood', 'cluttered_space', 'view']\n",
        "path = f'higan/boundaries/{indoor_model_name}/{attribute_name}_boundary.npy'\n",
        "\n",
        "# Boundary 파일 로드\n",
        "try:\n",
        "    boundary_file = np.load(path, allow_pickle=True).item()\n",
        "    boundary = boundary_file['boundary']\n",
        "    manipulate_layers = boundary_file['meta_data']['manipulate_layers']\n",
        "except ValueError:  # 만약 Boundary 파일 형식이 잘못된 경우\n",
        "    boundary = np.load(path)\n",
        "    manipulate_layers = '0-4' if attribute_name == 'view' else '6-11'\n",
        "\n",
        "# Layer-wise 조작 강도 설정\n",
        "if attribute_name == 'view':\n",
        "    strength = [1.0 for _ in range(indoor_model.num_layers)]  # 특정 Layer 조작 강도\n",
        "else:\n",
        "    strength = get_layerwise_manipulation_strength(\n",
        "        indoor_model.num_layers, indoor_model.truncation_psi, indoor_model.truncation_layers\n",
        "    )\n",
        "\n",
        "# Latent code 변환 (GPU -> CPU -> NumPy 배열)\n",
        "if isinstance(latent_code, torch.Tensor):  # 텐서인지 확인\n",
        "    latent_code_numpy = latent_code.detach().cpu().numpy()  # NumPy 배열로 변환\n",
        "else:\n",
        "    latent_code_numpy = latent_code  # 이미 NumPy 배열이라면 그대로 사용\n",
        "\n",
        "# Boundary도 NumPy 배열로 유지\n",
        "if isinstance(boundary, torch.Tensor):  # 만약 Boundary가 PyTorch 텐서라면\n",
        "    boundary_numpy = boundary.cpu().numpy()  # NumPy 배열로 변환\n",
        "else:\n",
        "    boundary_numpy = boundary\n",
        "\n",
        "# 조작 수행\n",
        "distance = -3  # 조작 거리 (-3.0 ~ 3.0)\n",
        "indoor_codes = manipulate(\n",
        "    latent_codes=latent_code_numpy,  # NumPy 배열 사용\n",
        "    boundary=boundary_numpy,  # NumPy 배열 사용\n",
        "    start_distance=0,\n",
        "    end_distance=distance,\n",
        "    step=2,\n",
        "    layerwise_manipulation=True,\n",
        "    num_layers=indoor_model.num_layers,\n",
        "    manipulate_layers=manipulate_layers,\n",
        "    is_code_layerwise=True,\n",
        "    is_boundary_layerwise=False,\n",
        "    layerwise_manipulation_strength=strength\n",
        ")\n",
        "\n",
        "# 불필요한 차원이 있는지 확인하고 제거\n",
        "if len(indoor_codes.shape) == 4:  # 잘못된 두 번째 차원인 경우\n",
        "    indoor_codes = indoor_codes[:, 0, :, :]  # 첫 번째 요소만 사용\n",
        "\n",
        "# 이미지 생성\n",
        "images = indoor_model.easy_synthesize(indoor_codes, latent_space_type='wp')['image']\n",
        "\n",
        "# 이미지 시각화\n",
        "imshow(images, col=1)  # 한 줄에 하나의 이미지 표시"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4gPRM1zBqdg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}